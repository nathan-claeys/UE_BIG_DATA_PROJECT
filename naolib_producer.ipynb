{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from kafka.admin import KafkaAdminClient, NewTopic\n",
    "from kafka.errors import TopicAlreadyExistsError, NoBrokersAvailable\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def create_topic_if_not_exists(\n",
    "    bootstrap_servers: str,\n",
    "    topic_name: str,\n",
    "    num_partitions: int = 1,\n",
    "    replication_factor: int = 1,\n",
    ") -> bool:\n",
    "    admin_client = None\n",
    "    try:\n",
    "        # Initialize Kafka Admin Client\n",
    "        admin_client = KafkaAdminClient(bootstrap_servers=bootstrap_servers)\n",
    "\n",
    "        # Fetch current topics\n",
    "        existing_topics = admin_client.list_topics()\n",
    "\n",
    "        if topic_name in existing_topics:\n",
    "            logger.info(\n",
    "                \"Topic '%s' already exists.\",\n",
    "                topic_name,\n",
    "            )\n",
    "            return\n",
    "\n",
    "        # Define new topic\n",
    "        topic = NewTopic(\n",
    "            name=topic_name,\n",
    "            num_partitions=num_partitions,\n",
    "            replication_factor=replication_factor,\n",
    "        )\n",
    "\n",
    "        # Create topic\n",
    "        admin_client.create_topics(new_topics=[topic], validate_only=False)\n",
    "        logger.info(\"Topic '%s' created successfully.\", topic_name)\n",
    "        return True\n",
    "\n",
    "    except TopicAlreadyExistsError:\n",
    "        logger.warning(\n",
    "            \"Topic '%s' already exists (caught exception).\",\n",
    "            topic_name,\n",
    "        )\n",
    "        return False\n",
    "\n",
    "    except NoBrokersAvailable:\n",
    "        logger.error(\n",
    "            \"No Kafka brokers available.\"\n",
    "            \" Check 'bootstrap_servers'configuration.\"\n",
    "        )\n",
    "        return False\n",
    "\n",
    "    except Exception as e:  # pylint: disable=broad-except\n",
    "        logger.error(\n",
    "            \"Failed to create topic %s: %s\",\n",
    "            topic_name,\n",
    "            e,\n",
    "        )\n",
    "        return False\n",
    "\n",
    "    finally:\n",
    "        if admin_client is not None:\n",
    "            admin_client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kafka_setup'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkafka\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KafkaProducer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkafka_setup\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_topic_if_not_exists\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m kafka_config\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kafka_setup'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "from kafka_setup import create_topic_if_not_exists\n",
    "import threading\n",
    "from constants import kafka_config\n",
    "\n",
    "stops_information = None\n",
    "\n",
    "\n",
    "def get_stops_information():\n",
    "    global stops_information\n",
    "    if stops_information is None:\n",
    "        response = requests.get(\"https://open.tan.fr/ewp/arrets.json\")\n",
    "        if response.status_code == 200:\n",
    "            stops_information = response.json()\n",
    "        else:\n",
    "            print(f\"Failed to fetch data: {response.status_code}\")\n",
    "    return stops_information\n",
    "\n",
    "\n",
    "def get_stops_of_line(line_name):\n",
    "    stops = []\n",
    "    for stop in get_stops_information():\n",
    "        for ligne in stop[\"ligne\"]:\n",
    "            if ligne[\"numLigne\"] == line_name:\n",
    "                stops.append(\n",
    "                    {\"codeLieu\": stop[\"codeLieu\"], \"libelle\": stop[\"libelle\"]}\n",
    "                )\n",
    "                break\n",
    "\n",
    "    return stops\n",
    "\n",
    "\n",
    "def get_nearby_bike_stations(\n",
    "    position: tuple, distance_in_kilometers: int\n",
    ") -> list:\n",
    "    base_url = \"https://data.nantesmetropole.fr\"\n",
    "    bike_stations_url = (\n",
    "        \"/api/explore/v2.1/catalog/datasets/\"\n",
    "        \"244400404_disponibilite-temps-reel-\"\n",
    "        \"velos-libre-service-naolib-nantes-metropole/records\"\n",
    "    )\n",
    "    position_str = f\"geom%27POINT({position[0]}%20{position[1]})%27\"\n",
    "    distance_str = f\"{distance_in_kilometers}km\"\n",
    "    filter_query = (\n",
    "        f\"?where=within_distance(position%2C%20{position_str}\"\n",
    "        f\"%2C%20{distance_str})\"\n",
    "    )\n",
    "    order_query = f\"&order_by=distance(position%2C%20{position_str})\"\n",
    "\n",
    "    limit_query = \"&limit=20\"\n",
    "    timezone_query = \"&timezone=Europe%2FParis\"\n",
    "\n",
    "    response = requests.get(\n",
    "        f\"{base_url}{bike_stations_url}{filter_query}\"\n",
    "        f\"{order_query}{limit_query}{timezone_query}\",\n",
    "        timeout=5,\n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data[\"results\"]\n",
    "    else:\n",
    "        print(f\"Failed to fetch data: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_trams_gare_nord():\n",
    "    url = \"https://open.tan.fr/ewp/horairesarret.json/GSNO\"\n",
    "    response_1_1 = requests.get(url + \"1/1/2\")  # tram 1 sens 1\n",
    "    response_1_2 = requests.get(url + \"2/1/1\")  # tram 1 sens 2\n",
    "    if response_1_1.status_code == 200 and response_1_2.status_code == 200:\n",
    "        data_1_1 = response_1_1.json()\n",
    "        data_1_2 = response_1_2.json()\n",
    "        return (data_1_1.get(\"horaires\"), data_1_2.get(\"horaires\"))  # \"horaires\":[{\"heure\":\"4h\",\"passages\":[\"50d\"]},{\"heure\":\"5h\",\"passages\":[\"12\",\"32\",\"52\"]}]\n",
    "    else:\n",
    "        print(\n",
    "            f\"Failed to fetch data: {response_1_1.status_code},\"\n",
    "            f\" {response_1_2.status_code}\"\n",
    "        )\n",
    "        return [], []\n",
    "\n",
    "\n",
    "def send_bike_stations(position, radius):\n",
    "    topic = \"bike_stations\"\n",
    "\n",
    "    # Initialize Kafka Producer\n",
    "    producer = KafkaProducer(\n",
    "        bootstrap_servers=kafka_config[\"bootstrap_servers\"],\n",
    "        value_serializer=lambda v: json.dumps(v).encode(\"utf-8\"),\n",
    "    )\n",
    "\n",
    "    print(\"Starting to collect bike station data...\")\n",
    "\n",
    "    records = 0\n",
    "\n",
    "    bike_stations = get_nearby_bike_stations(position, radius)\n",
    "\n",
    "    for station in bike_stations:\n",
    "        producer.send(topic, value=station)\n",
    "        records += 1\n",
    "\n",
    "    producer.flush()\n",
    "    print(f\"Sent {records} records.\")\n",
    "\n",
    "\n",
    "def send_bus_position(line_name):\n",
    "    topic = \"bus_position\"\n",
    "\n",
    "    # Initialize Kafka Producer\n",
    "    producer = KafkaProducer(\n",
    "        bootstrap_servers=kafka_config[\"bootstrap_servers\"],\n",
    "        value_serializer=lambda v: json.dumps(v).encode(\"utf-8\"),\n",
    "    )\n",
    "\n",
    "    print(\"Starting to collect bus position data...\")\n",
    "\n",
    "    records = 0\n",
    "\n",
    "    for stop in get_stops_of_line(line_name):\n",
    "\n",
    "        url = (\n",
    "            \"https://open.tan.fr/ewp/tempsattentelieu.json/\"\n",
    "            f\"{stop['codeLieu']}/\"\n",
    "            f\"1/{line_name}\"\n",
    "        )\n",
    "\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "\n",
    "            # Publish each entry to Kafka\n",
    "            for info in data:\n",
    "                info[\"stop\"] = stop[\"codeLieu\"]\n",
    "                info[\"codeArret\"] = info[\"arret\"][\"codeArret\"]\n",
    "                info[\"numLigne\"] = info[\"ligne\"][\"numLigne\"]\n",
    "                del info[\"ligne\"]\n",
    "                del info[\"arret\"]\n",
    "                producer.send(topic, value=info)\n",
    "                records += 1\n",
    "\n",
    "        else:\n",
    "            print(f\"Failed to fetch data: {response.status_code}\")\n",
    "\n",
    "    producer.flush()\n",
    "    print(f\"Sent {records} records.\")\n",
    "\n",
    "\n",
    "def send_trams_gare_nord():\n",
    "    topic = \"trams_gare_nord\"\n",
    "\n",
    "    # Initialize Kafka Producer\n",
    "    producer = KafkaProducer(\n",
    "        bootstrap_servers=kafka_config[\"bootstrap_servers\"],\n",
    "        value_serializer=lambda v: json.dumps(v).encode(\"utf-8\"),\n",
    "    )\n",
    "\n",
    "    print(\"Starting to collect tram data...\")\n",
    "\n",
    "    records = 0\n",
    "\n",
    "    data1, data2 = get_trams_gare_nord()\n",
    "\n",
    "    for info in data1:\n",
    "        info[\"sens\"] = 1\n",
    "        producer.send(topic, value=info)\n",
    "        records += 1\n",
    "\n",
    "    for info in data2:\n",
    "        info[\"sens\"] = 2\n",
    "        producer.send(topic, value=info)\n",
    "        records += 1\n",
    "\n",
    "    producer.flush()\n",
    "    print(f\"Sent {records} records.\")\n",
    "\n",
    "\n",
    "def send_trams_gare_nord():\n",
    "    topic = \"trams_gare_nord\"\n",
    "\n",
    "    # Initialize Kafka Producer\n",
    "    producer = KafkaProducer(\n",
    "        bootstrap_servers=kafka_config[\"bootstrap_servers\"],\n",
    "        value_serializer=lambda v: json.dumps(v).encode(\"utf-8\"),\n",
    "    )\n",
    "\n",
    "    print(\"Starting to collect tram data...\")\n",
    "\n",
    "    records = 0\n",
    "\n",
    "    data1, data2 = get_trams_gare_nord()\n",
    "\n",
    "    for info in data1:\n",
    "        producer.send(topic, value=info)\n",
    "        records += 1\n",
    "\n",
    "    for info in data2:\n",
    "        producer.send(topic, value=info)\n",
    "        records += 1\n",
    "\n",
    "    producer.flush()\n",
    "    print(f\"Sent {records} records.\")\n",
    "\n",
    "\n",
    "def run_periodic(interval_sec, stop_event, task, task_args=()):\n",
    "    while not stop_event.is_set():\n",
    "        task(*task_args)\n",
    "        # Wait for the interval or until stop is requested\n",
    "        stop_event.wait(interval_sec)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    create_topic_if_not_exists(\n",
    "        kafka_config[\"bootstrap_servers\"],\n",
    "        \"bus_position\",\n",
    "    )\n",
    "    create_topic_if_not_exists(\n",
    "        kafka_config[\"bootstrap_servers\"],\n",
    "        \"trams_gare_nord\",\n",
    "    )\n",
    "    create_topic_if_not_exists(\n",
    "        kafka_config[\"bootstrap_servers\"],\n",
    "        \"bike_stations\",\n",
    "    )\n",
    "\n",
    "    # Non periodic task\n",
    "    send_trams_gare_nord()\n",
    "\n",
    "    TEST_POSITION = (-1.520754797081473, 47.282105501965894)\n",
    "    TEST_RADIUS = 10\n",
    "    print(get_nearby_bike_stations(TEST_POSITION, TEST_RADIUS))\n",
    "    stop_event = threading.Event()\n",
    "\n",
    "    # Create the periodic thread for bus position data\n",
    "    bus_thread = threading.Thread(\n",
    "        target=run_periodic, args=(60, stop_event, send_bus_position, (\"C6\",))\n",
    "    )\n",
    "\n",
    "    # Create another periodic thread for bike station data\n",
    "    bike_thread = threading.Thread(\n",
    "        target=run_periodic,\n",
    "        args=(\n",
    "            120,\n",
    "            stop_event,\n",
    "            send_bike_stations,\n",
    "            (TEST_POSITION, TEST_RADIUS),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Start both threads\n",
    "    bus_thread.start()\n",
    "    bike_thread.start()\n",
    "\n",
    "    try:\n",
    "        # Keep the main thread alive while the periodic threads are running\n",
    "        while bus_thread.is_alive() or bike_thread.is_alive():\n",
    "            bus_thread.join(timeout=1)\n",
    "            bike_thread.join(timeout=1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupt received, shutting down gracefully...\")\n",
    "        stop_event.set()\n",
    "        bus_thread.join()\n",
    "        bike_thread.join()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
